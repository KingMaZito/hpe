\section{conclusion}
As research in the topic of human pose estimation is increasing, it becomes more important to have an overview about methods used in this field. Therefore, this paper presented selected works of the last years. First commonly used datasets were described, followed by metrics for benchmarking to be able to compare different methods against each other. After that, as a representative of models in (3d) human pose estimation, SMPL was introduced in \autoref{sec:SMPL}. 
\\2d pose estimation was next. Since neural networks are currently the most powerful tools in this area, challenges when designing those have to be discussed first. The top-down approach, which divides input images such that only a single person appears on one part, was now further investigated. While heat-map-based approaches are the most precise at the moment, regression-based methods with convolutional neural networks are more efficient in scenarios where real-time performance is important, because they are not as computationally expensive compared to the many steps a heat-map method needs. Also, training is easier with regression-based methods, as it can be done in an end-to-end fashion. Unlike top-down methods, bottom-up approaches try to estimate joint positions from an input image first, and then merge them to individual humans. Since the pose is not calculated for each human individual, these methods are faster than their top-down complement for the most part when multiple humans can be found in an image, because the performance of top-down approaches drops with the number of human poses to be estimated increasing. However, if not many persons are to be found (and they dont overlap each other), top-down methods yield higher performance. Future research needs to be focussed to improve computational speed even further to make real-time applications possible, and decrease failure rates in scenarios with many humans or occlusion.
\\ In 3d human pose estimation, the lack of 3d datasets of humans in-the-wild for training and testing neural networks should be addressed in the future, because just like in 2d human pose estimation, neural networks currently play a huge role in this field. Uplifting an already estimated pose in two dimensions to the third one has been one of the recent approaches in the past years to make up for the missing training data. However, this method relies heavily on the correctness of the 2d estimation, as it can not correct it. Performance-wise, the uplifting process does not need to be very complex computationally, which was shown by Martinez et al. in \cite{Martinez_2017_ICCV}. A different method, which used multiple reprojections of the generated 3d pose estimation to 2d to employ Single-view-multi-angle Consistency, was described too as a representative for unsupervised uplifting methods. The next approach, estimating a 3d pose directly from a 2d image was discussed. The get rid of the problem of missing in-the-wild training data, the methods presented here used a multitask network for 2d and 3d pose estimation or a previously seperately trained autoencoder. Working directly on 3d data yields high accuracy and robustness in exchange for high computational complexity and demand for a lot of computational resources. Since 3d data is not available in most applications in the near, this approach is not as important for future research though. Lastly, methods working with human 3d models, such as the previously described SMPL, could be presented. 